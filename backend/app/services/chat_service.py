from langchain_core.messages import HumanMessage
from app.llm.graph import graph  # compiled graph

# üîí In-memory session store (DEV ONLY)
SESSION_STORE = {}


def generate_response(user_message: str, session_id: str) -> str:
    # 1Ô∏è‚É£ Initialize memory if new session
    if session_id not in SESSION_STORE:
        SESSION_STORE[session_id] = {
            "messages": []
        }

    # 2Ô∏è‚É£ Append user message to memory
    SESSION_STORE[session_id]["messages"].append(
        HumanMessage(content=user_message)
    )

    # 3Ô∏è‚É£ Invoke LangGraph WITH FULL STATE
    result = graph.invoke(SESSION_STORE[session_id])

    # 4Ô∏è‚É£ Persist updated state
    SESSION_STORE[session_id] = result

    # 5Ô∏è‚É£ Return last AI message
    return result["messages"][-1].content
